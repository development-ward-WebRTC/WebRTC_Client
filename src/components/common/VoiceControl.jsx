import React, { useState, useEffect, useRef } from "react";

const VoiceControl = ({ peerConnection, connectionState }) => {
  const [isVoiceEnabled, setIsVoiceEnabled] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [error, setError] = useState("");
  const [warningShown, setWarningShown] = useState(false);
  const localStreamRef = useRef(null);
  const remoteAudioRef = useRef(null);
  const trackAddedRef = useRef(false); // íŠ¸ë™ì´ ì´ë¯¸ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ ì¶”ì 

  const startVoice = async () => {
    try {
      setError("");

      // ì—°ê²° ìƒíƒœ í™•ì¸
      const pc = peerConnection;
      console.log("VoiceControl startVoice - trackAdded:", trackAddedRef.current, "hasStream:", !!localStreamRef.current, "signalingState:", pc?.signalingState);

      // ì´ë¯¸ ìŠ¤íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ ê·¸ëƒ¥ í™œì„±í™”ë§Œ
      if (localStreamRef.current && trackAddedRef.current) {
        localStreamRef.current.getAudioTracks().forEach((track) => {
          track.enabled = true;
        });
        setIsVoiceEnabled(true);
        setIsMuted(false);
        console.log("Voice chat re-enabled (track already added)");
        return;
      }

      // PC í™•ì¸
      if (!pc) {
        setError("ì—°ê²°ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.");
        return;
      }
      
      if (pc.signalingState === "closed") {
        if (!warningShown) {
          alert("âš ï¸ WebRTC ì—°ê²°ì´ ë‹«í˜”ìŠµë‹ˆë‹¤.\n\nìŒì„± ì±„íŒ…ì„ ì‚¬ìš©í•˜ë ¤ë©´:\n1. ë¡œë¹„ë¡œ ëŒì•„ê°€ê¸°\n2. ìƒˆë¡œìš´ ë°© ìƒì„±\n3. ê²Œì„ ì‹œì‘ í›„ ë°”ë¡œ ìŒì„± í™œì„±í™”\n\ní˜„ì¬ ê²Œì„ì€ ê³„ì† ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.");
          setWarningShown(true);
        }
        setError("WebRTC ì—°ê²°ì´ ë‹«í˜”ìŠµë‹ˆë‹¤. ìƒˆ ê²Œì„ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.");
        return;
      }

      // ë¸Œë¼ìš°ì € ë¯¸ë””ì–´ ì§€ì› í™•ì¸ ë° ë””ë²„ê¹…
      console.log("ğŸ” Checking media support:", {
        hasNavigator: !!navigator,
        hasMediaDevices: !!navigator?.mediaDevices,
        hasGetUserMedia: !!navigator?.mediaDevices?.getUserMedia,
        isSecureContext: window.isSecureContext,
        protocol: window.location.protocol,
      });

      // getUserMedia ì°¸ì¡° í™•ì¸ (React DevTools hook ìš°íšŒ)
      const getUserMedia = navigator?.mediaDevices?.getUserMedia?.bind(navigator.mediaDevices)
        || navigator?.getUserMedia?.bind(navigator)
        || navigator?.webkitGetUserMedia?.bind(navigator)
        || navigator?.mozGetUserMedia?.bind(navigator);

      if (!getUserMedia) {
        setError("ì´ ë¸Œë¼ìš°ì €ëŠ” ë§ˆì´í¬ ì ‘ê·¼ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
        console.error("getUserMedia is not supported in this browser");
        return;
      }

      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ (ì²« ë²ˆì§¸ë§Œ)
      let stream;
      try {
        // ìµœì‹  API ìš°ì„  ì‹œë„
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true,
            },
            video: false,
          });
        } else {
          // ë ˆê±°ì‹œ API í´ë°±
          stream = await new Promise((resolve, reject) => {
            getUserMedia(
              { audio: true, video: false },
              resolve,
              reject
            );
          });
        }
      } catch (getUserMediaError) {
        console.error("getUserMedia error:", getUserMediaError);
        throw getUserMediaError;
      }

      if (!stream) {
        setError("ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return;
      }

      localStreamRef.current = stream;
      console.log("âœ… Got media stream:", stream.getTracks());

      // ì˜¤ë””ì˜¤ íŠ¸ë™ì„ PeerConnectionì— ì¶”ê°€ (ì²« ë²ˆì§¸ë§Œ)
      if (pc && pc.signalingState !== "closed" && !trackAddedRef.current) {
        stream.getTracks().forEach((track) => {
          if (track.kind === "audio") {
            try {
              pc.addTrack(track, stream);
              trackAddedRef.current = true;
              console.log("Audio track added successfully");
            } catch (err) {
              console.error("Failed to add track:", err);
              setError("ì˜¤ë””ì˜¤ íŠ¸ë™ ì¶”ê°€ ì‹¤íŒ¨. ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
              stream.getTracks().forEach((t) => t.stop());
              return;
            }
          }
        });
      } else if (trackAddedRef.current) {
        console.log("Track already added, just enabling");
      } else {
        console.error("PeerConnection is closed. Cannot add track.");
        setError("ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê²Œì„ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.");
        stream.getTracks().forEach((t) => t.stop());
        return;
      }

      setIsVoiceEnabled(true);
      setIsMuted(false);
      console.log("Voice chat started");
    } catch (err) {
      console.error("Failed to start voice chat:", err);
      if (err.name === "NotAllowedError" || err.name === "PermissionDeniedError") {
        setError("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤");
      } else if (err.name === "NotFoundError" || err.name === "DevicesNotFoundError") {
        setError("ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
      } else {
        setError("ë§ˆì´í¬ ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤");
      }
    }
  };

  const stopVoice = () => {
    if (localStreamRef.current) {
      // íŠ¸ë™ì„ ì™„ì „íˆ ì¢…ë£Œí•˜ì§€ ì•Šê³  ë¹„í™œì„±í™”ë§Œ (ì¬ì‚¬ìš© ê°€ëŠ¥)
      localStreamRef.current.getAudioTracks().forEach((track) => {
        track.enabled = false;
      });
    }
    setIsVoiceEnabled(false);
    setIsMuted(false);
    console.log("Voice chat disabled (track kept for reuse)");
  };

  const toggleMute = () => {
    if (localStreamRef.current) {
      localStreamRef.current.getAudioTracks().forEach((track) => {
        track.enabled = !track.enabled;
      });
      setIsMuted(!isMuted);
    }
  };

  const toggleVoice = () => {
    if (isVoiceEnabled) {
      stopVoice();
    } else {
      startVoice();
    }
  };

  useEffect(() => {
    const pc = peerConnection;
    if (!pc || pc.signalingState === "closed") return;

    // ì›ê²© ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
    const handleTrack = (event) => {
      console.log("Received remote audio track");
      if (remoteAudioRef.current && event.streams[0]) {
        remoteAudioRef.current.srcObject = event.streams[0];
      }
    };

    pc.addEventListener("track", handleTrack);

    return () => {
      pc.removeEventListener("track", handleTrack);
      // cleanup ì‹œ ì™„ì „íˆ ì¢…ë£Œ
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach((track) => {
          track.stop();
        });
        localStreamRef.current = null;
      }
      trackAddedRef.current = false;
    };
  }, [peerConnection]);

  // ì—°ê²° ìƒíƒœ í™•ì¸
  const pc = peerConnection;
  const signalingState = pc?.signalingState;
  const pcConnectionState = pc?.connectionState;
  
  // ë²„íŠ¼ í™œì„±í™” ì¡°ê±´:
  // 1. PCê°€ ì¡´ì¬í•˜ê³ 
  // 2. signalingStateê°€ closedê°€ ì•„ë‹ˆê³  (ë˜ëŠ” stable, have-local-offer ë“±)
  // 3. connectionStateê°€ closedê°€ ì•„ë‹˜
  const isConnected = !!pc && signalingState !== "closed" && pcConnectionState !== "closed";
  
  // ë””ë²„ê¹…ìš©
  useEffect(() => {
    console.log("ğŸ¤ VoiceControl render:", {
      hasPeerConnection: !!pc,
      signalingState: signalingState,
      connectionState: connectionState,
      pcConnectionState: pc?.connectionState,
      iceConnectionState: pc?.iceConnectionState,
      hasLocalDescription: !!pc?.localDescription,
      hasRemoteDescription: !!pc?.remoteDescription,
      isConnected: isConnected,
    });
  }, [pc, signalingState, connectionState, isConnected]);

  return (
    <div className="flex items-center gap-3">
      {/* ì›ê²© ì˜¤ë””ì˜¤ (ìˆ¨ê¹€) */}
      <audio ref={remoteAudioRef} autoPlay />

      {/* ìŒì„± ON/OFF ë²„íŠ¼ - changed from green/gray to blue card game style */}
      <button
        onClick={toggleVoice}
        disabled={!isConnected}
        className={`px-5 py-2 rounded-lg font-bold transition-all ${
          !isConnected
            ? "bg-gradient-to-b from-gray-800 to-gray-900 text-gray-500 border border-gray-700 cursor-not-allowed opacity-50"
            : isVoiceEnabled
            ? "bg-gradient-to-b from-blue-600 to-blue-700 text-white border border-blue-500 shadow-lg shadow-blue-500/30 hover:shadow-blue-500/50 hover:scale-105"
            : "bg-gradient-to-b from-gray-700 to-gray-800 text-gray-300 border border-gray-600 shadow-lg shadow-gray-600/20 hover:shadow-gray-600/40 hover:scale-105"
        }`}
        title={
          !isConnected
            ? `ê²Œì„ ì—°ê²° í›„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤ (ìƒíƒœ: ${connectionState || "unknown"})`
            : isVoiceEnabled
            ? "ìŒì„± ì±„íŒ… ë„ê¸°"
            : "ìŒì„± ì±„íŒ… ì¼œê¸°"
        }
      >
        ğŸ¤ {isVoiceEnabled ? "ON" : "OFF"}
      </button>

      {/* ìŒì†Œê±° ë²„íŠ¼ (ìŒì„± í™œì„±í™” ì‹œì—ë§Œ í‘œì‹œ) - changed from red/blue to blue card game style */}
      {isVoiceEnabled && (
        <button
          onClick={toggleMute}
          className={`px-5 py-2 rounded-lg font-bold transition-all ${
            isMuted
              ? "bg-gradient-to-b from-red-700 to-red-800 text-white border border-red-600 shadow-lg shadow-red-600/30 hover:shadow-red-600/50 hover:scale-105"
              : "bg-gradient-to-b from-blue-600 to-blue-700 text-white border border-blue-500 shadow-lg shadow-blue-500/30 hover:shadow-blue-500/50 hover:scale-105"
          }`}
          title={isMuted ? "ìŒì†Œê±° í•´ì œ" : "ìŒì†Œê±°"}
        >
          {isMuted ? "ğŸ”‡ ìŒì†Œê±°" : "ğŸ”Š í™œì„±"}
        </button>
      )}

      {/* ì—ëŸ¬/ê²½ê³  ë©”ì‹œì§€ */}
      {error && <span className="text-red-400 text-sm font-semibold">{error}</span>}
      {!error && signalingState === "closed" && (
        <span className="text-yellow-400 text-sm">âš ï¸ ì—°ê²° ëŠê¹€ (ê²Œì„ ì¬ì‹œì‘ í•„ìš”)</span>
      )}
    </div>
  );
};

export default VoiceControl;
